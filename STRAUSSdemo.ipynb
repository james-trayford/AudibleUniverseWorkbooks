{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/james-trayford/AudibleUniverseWorkbooks/blob/group4/STRAUSSdemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXMXgH-xVgaX"
      },
      "source": [
        "Notebook prepared by **Dr James Trayford** - for queries please email [`james.trayford@port.ac.uk`](mailto:james.trayford@port.ac.uk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBwYdDYB9lCQ"
      },
      "source": [
        "To use this notebook (if you haven't already) you can first save a copy to your local drive by clicking `File > Save a Copy in Drive` and run on that copy. `Edit > Clear all outputs` on that copy should also ensure yopu have a clean version\n",
        " to start from."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v47s4t152sZ6"
      },
      "source": [
        "## **0. Introduction**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EMw6AfO200J"
      },
      "source": [
        "We will be using the [STRAUSS code](https://github.com/james-trayford/strauss) for this activity\n",
        "\n",
        "<img src=\"https://github.com/james-trayford/strauss/blob/main/misc/strauss_logo.png?raw=true\">\n",
        "\n",
        "For reference, you can read an overview of the code (as well as detailed documentation) [at this link](https://strauss.readthedocs.io/en/latest/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ7CisIn22sg"
      },
      "source": [
        "`strauss` is an open source, object-oriented python library intended to be a flexible toolkit and engine for sonification, allowing detailed low-level control over the sonification process. Simultaneously, casual users can quickly hear their data, adapting a library of python notebook templates for a range of applications. \n",
        "\n",
        "By analogy to visualisation, the intention is to provide something akin to a plotting library. A library allows users to make a variety of simple plots easily, but also the option to control all aspects of plots and adapt them to the intricacies of their data, for optimal presentation. \n",
        "\n",
        "By adopting a general approach, `strauss` is intended to sonify any form of data for users with differing expertise. `strauss` is work in progress, and benefits form user feedback - filling in this feedback will be very useful in making the code better!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m0bIZRs7BaC"
      },
      "source": [
        "### **This notebook:** \n",
        "This notebook will demonstrate some of the ways in which `strauss` can be applied to sonify light curves. Alternative options may be demonstrated with commented out code ( i.e. lines of actual code preceded by `#`) - feel free to try these! Generally the goal of this notebook is to give some open examples to explore the code and experiment, so please do so! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMh0Lo6E8lc9"
      },
      "source": [
        "### **STRAUSS video**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQHg0a5Z5jB_"
      },
      "source": [
        "You can also run the below cell to see a 12 minute introduction video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVzULp-G4ZMz"
      },
      "outputs": [],
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('yhSNM8ztSEk', width=800, height=600) "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q6ScbV3u_gLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zJMkFJwTTC9"
      },
      "source": [
        "## **1. Setup:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH3ld6PZP2vX"
      },
      "source": [
        "First, let's install `strauss`! Just run the code cell below.\n",
        "\n",
        "*We will use the `spectraliser` development branch for this notebook. Install can take a while - but you should only need to run it once!*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgF2VVpZPl_V"
      },
      "outputs": [],
      "source": [
        " !pip --quiet install git+https://github.com/james-trayford/strauss.git@spectraliser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrRwGGvJdIP6"
      },
      "source": [
        "and also make a local copy of the repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqHJTrrTdBhB"
      },
      "outputs": [],
      "source": [
        " !git clone https://github.com/james-trayford/strauss.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4FQXd9fUkfr"
      },
      "source": [
        "Make plots appear in-line by default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9_unXRNUgim"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYvyH45vTR-b"
      },
      "source": [
        "Import the modules we need..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0rPodqYQorM"
      },
      "outputs": [],
      "source": [
        "# strauss imports\n",
        "from strauss.sonification import Sonification\n",
        "from strauss.sources import Events, Objects\n",
        "from strauss import channels\n",
        "from strauss.score import Score\n",
        "from strauss.generator import Sampler, Synthesizer, Spectralizer\n",
        "from strauss import sources as Sources \n",
        "import strauss\n",
        "\n",
        "# other useful modules\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from scipy.signal import savgol_filter\n",
        "import urllib.request\n",
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "import yaml\n",
        "import pandas as pd\n",
        "\n",
        "# modules to display in-notebook\n",
        "import IPython.display as ipd\n",
        "from IPython.core.display import display, Markdown, Latex, Image\n",
        "\n",
        "# set figures to be a decent size by default\n",
        "import matplotlib\n",
        "font = {'family' : 'sans-serif',\n",
        "        'weight' : 'normal',\n",
        "        'size'   : 18}\n",
        "matplotlib.rc('font', **font)\n",
        "matplotlib.rc('figure', **{'figsize':[14.0, 7.0]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kUJV_oI8mqD"
      },
      "source": [
        "## **2. Getting the Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCFYP7KUP462"
      },
      "source": [
        "âš   ***The cells in this section are to organise the data we need for the session, don't worry too much about the details of the code here!*** âš  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nykq-9yBJAfE"
      },
      "source": [
        "First, let's download the data for this session to somewhere we have `Colab` access"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cNnI7xN9lTM"
      },
      "outputs": [],
      "source": [
        "outdir = \"./AU2_Group4\"\n",
        "\n",
        "path = os.path.realpath(outdir)\n",
        "if not glob.glob(outdir): \n",
        "  os.mkdir(path)  \n",
        "    \n",
        "fname = \"Group4_input_data.zip\"\n",
        "url = \"https://drive.google.com/uc?export=download&id=1hZYDckpHnWWdZXOAavFOcieeZP42WGJr\"\n",
        "\n",
        "print(f\"Downloading files...\")\n",
        "with urllib.request.urlopen(url) as response, open(f\"{path}/{fname}\", 'wb') as out_file:\n",
        "  data = response.read() # a `bytes` object\n",
        "  out_file.write(data)\n",
        "\n",
        "print(f\"Unzipping files to {outdir}/Data ...\")\n",
        "with zipfile.ZipFile(f\"{outdir}/{fname}\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(f\"{outdir}\")\n",
        "\n",
        "print(f\"Clearing up...\")\n",
        "os.remove(f\"{path}/{fname}\")\n",
        "\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGluXHJHYGqS"
      },
      "source": [
        "We now have access to all the data for this group - let's see what's available and make some plots..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAbG8PNrYDof"
      },
      "outputs": [],
      "source": [
        "for f in glob.glob('./AU2_Group4/Data/csv/*.csv'):\n",
        "  data_table = pd.read_csv(f)\n",
        "  display(Markdown(f\"### File: <mark>`{f}`</mark>\"))\n",
        "  xlab = data_table.columns[0]\n",
        "  ylab = data_table.columns[1]\n",
        "  plt.plot(data_table[xlab], data_table[ylab])\n",
        "  plt.xlabel(f'{xlab}')\n",
        "  plt.ylabel(f'{ylab}')\n",
        "  plt.show()\n",
        "  print(data_table.head())\n",
        "  #display(data_table)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO4y_pIS0_No"
      },
      "source": [
        "## **3. One-dimensional time series sonification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF0wzdSYjvp7"
      },
      "source": [
        "Here we will sonify observed light-curves as a ***one-dimensional time series*** , where some ***sound property*** is is varied with ***time*** in the ***sonification***, in the same way that **flux density**, varies with ***time*** in a ***light curve*** (early in the sonification is earlier observation time, later in the sonification is later observation time)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCE-nk67Lf5N"
      },
      "source": [
        "### 3.1 Trying the `Events` source function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4DnjcHnSsLd"
      },
      "source": [
        "In `strauss` we could treat each ***flux density*** data point in the light curve as separate audio `Events`, with an occurence `time` mapped from their ***time***. \n",
        "\n",
        "However, articulating each data point as a separate ***note*** for ***many thousands*** of data points can require long and drawn-out sonifications. \n",
        "\n",
        "Here we demonstrate this approach with just a portion of the data points (staying within `Colab`'s RAM limitations for unpaid users ðŸ¤«). We use the `Synthesizer` object with the `pitch_mapper` preset by default - this has a default pitch range of ***two octaves*** (a factor of 4 in frequency) and we pick an `E3` note (165 Hz) as the base (lowest) frequency.\n",
        "\n",
        "We will hear the **flux** of each point as `pitch`, with their time mapped to the occurence `time` (moving from low to high time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0ibVd2VLdzd"
      },
      "outputs": [],
      "source": [
        "display(Markdown(f\"### Sonifying in 1D using '`Events`' object:\"))\n",
        "\n",
        "# read in the various data file - can uncomment lines to hear other files - the last\n",
        "# uncommented `data_table` line will be the diosplayed file. \n",
        "data_table = np.genfromtxt(\"./AU2_Group4/Data/csv/GALEX_NUV_LC.csv\", delimiter=',')[1:]\n",
        "#data_table = np.genfromtxt(\"./AU2_Group4/Data/csv/tic_lc.csv\", delimiter=',')[1:]\n",
        "#data_table = np.genfromtxt(\"./AU2_Group4/Data/csv/kid11616200_lc.csv\", delimiter=',')[1:]\n",
        "\n",
        "# grab times and fluxes from chosen data file\n",
        "time = data_table[:,0]\n",
        "flux = data_table[:,1]\n",
        "\n",
        "# show light curve again, for reference\n",
        "plt.scatter(time, flux, s=4)\n",
        "plt.ylabel('Flux Density')\n",
        "plt.xlabel('time [nm]')\n",
        "plt.show()\n",
        "\n",
        "%matplotlib notebook\n",
        "# specify the base notes used. In this example we use a single E3 note and \n",
        "# freely vary the pitch via the 'pitch_shift' parameter \n",
        "notes = [[\"E3\"]]\n",
        "\n",
        "# we could also just specify a particular frequency...\n",
        "#notes = [[150.]]\n",
        "\n",
        "score =  Score(notes, 30)\n",
        "\n",
        "\n",
        "data = {'pitch':np.ones(flux.size),\n",
        "        'time': time,\n",
        "        'pitch_shift':flux}\n",
        "\n",
        "# specify audio system (e.g. mono, stereo, 5.1, ...)\n",
        "system = \"mono\"\n",
        "\n",
        "# set up synth (this generates the sound using mathematcial waveforms)\n",
        "generator = Synthesizer()\n",
        "generator.load_preset('pitch_mapper')\n",
        "\n",
        "# or maybe the sampler instead by uncommenting this block (this uses recorded audio clips)\n",
        "#generator = Sampler(sampfiles=\"./strauss/data/samples/mallets\")\n",
        "#generator.modify_preset({'phi': 0,'theta':0,})\n",
        "\n",
        "generator.modify_preset({'note_length':0.15,\n",
        "                         'volume_envelope': {'use':'on',\n",
        "                                             'D':0.1,\n",
        "                                             'S':0.,\n",
        "                                             'A':0.01}})\n",
        "\n",
        "# set 0 to 100 percentile limits so the full pitch range is used...\n",
        "# setting 0 to 101 for pitch means the sonification is 1% longer than \n",
        "lims = {'time': ('0','101'),\n",
        "        'pitch_shift': ('0','100')}\n",
        "\n",
        "# set up source\n",
        "sources = Events(data.keys())\n",
        "sources.fromdict(data)\n",
        "sources.apply_mapping_functions(map_lims=lims)\n",
        "\n",
        "soni = Sonification(score, sources, generator, system)\n",
        "soni.render()\n",
        "dobj = soni.notebook_display()\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWkgTFk3T5rL"
      },
      "source": [
        "The articulation of each note lets you hear each data point separately, but over many noisy data points can lead to a confusing result - it's hard to keep track of the fluxes and our pitch memory is challenged.\n",
        "\n",
        "Instead we can try ***smoothly evolving*** parameters, designating the light curves as an ***evolving `Object`*** source class. We demonstrate this in the following subsection `3.1`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvWzJ2JrlrHP"
      },
      "source": [
        "### 3.2 Instead Trying the `Objects` Source Type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohlCzjEysV3N"
      },
      "source": [
        "Let's first try the evolving `Object` approach without modifying the raw data in any way. In analogy to visual display, the `Event` representation is like plotting the light curve as a scatter plot, while an `Object` representation is like plotting the light curve as a continuous line.\n",
        "\n",
        " We set up some parameters for `strauss`, e.g. choosing a sonification length of `40` seconds. A longer sonification might let you hear more detail, but will take longer to listen to (and for `Colab` to load!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nD7c6QR1NiJ"
      },
      "outputs": [],
      "source": [
        "# specify audio system (e.g. mono, stereo, 5.1, ...)\n",
        "system = \"mono\"\n",
        "\n",
        "# length of the sonification in s\n",
        "length = 40.\n",
        "\n",
        "# set up synth and turn on LP filter\n",
        "generator = Synthesizer()\n",
        "generator.load_preset('pitch_mapper')\n",
        "generator.preset_details('pitch_mapper')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woJrlbVGcsmP"
      },
      "source": [
        "Let's pick a light curve to sonify (as in Section 2). We will again default to ***Type 1*** light curve `'51788-0386-086'`.\n",
        "\n",
        "Try changing this if you want to explore different light curves!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMp2Wq5Ocmq1"
      },
      "outputs": [],
      "source": [
        "# read in the various data file - can uncomment lines to hear other files - the last\n",
        "# uncommented `data_table` line will be the diosplayed file. \n",
        "data_table = np.genfromtxt(\"./AU2_Group4/Data/csv/GALEX_NUV_LC.csv\", delimiter=',')[1:]\n",
        "#data_table = np.genfromtxt(\"./AU2_Group4/Data/csv/tic_lc.csv\", delimiter=',')[1:]\n",
        "#data_table = np.genfromtxt(\"./AU2_Group4/Data/csv/kid11616200_lc.csv\", delimiter=',')[1:]\n",
        "\n",
        "# grab times and fluxes from chosen data file\n",
        "time = data_table[:,0]\n",
        "flux = data_table[:,1]\n",
        "\n",
        "# Finally, plot the light curve to remind us what we're working with\n",
        "plt.plot(time,flux)\n",
        "plt.xlabel(f'Time')\n",
        "plt.ylabel(f'Flux')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0K2YmC4C18a"
      },
      "source": [
        "let's hear the 1D time-series data sonification, mapping flux density to pitch for the light curve.\n",
        "\n",
        "*NB: If you were wondering why `strauss` refers to the varying pitch mapping as `pitch_shift` and not just `pitch`, this is because all sources in `strauss` also need a base `pitch` which is chosen from the `'notes'` structure (here always `'A2'`) by the `Score`. This is because `strauss` can play many sources at the same time! Again, you can read more about this [in the docs](https://strauss.readthedocs.io/en/latest/).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeBqkWEk1Zny"
      },
      "outputs": [],
      "source": [
        "display(Markdown(f\"### Sonifying in 1D using '`pitch_shift`':\"))\n",
        "\n",
        "# show light curve again, for reference\n",
        "plt.plot(time,flux)\n",
        "plt.xlabel(f'Time')\n",
        "plt.ylabel(f'Flux')\n",
        "plt.show()\n",
        "\n",
        "%matplotlib notebook\n",
        "notes = [[\"A3\"]]\n",
        "score =  Score(notes, length)\n",
        "\n",
        "data = {'pitch':1.,\n",
        "        'time_evo':time,\n",
        "        'pitch_shift':flux}\n",
        "\n",
        "# set 0 to 100 percentile limits so the full pitch and time range is used...\n",
        "lims = {'time_evo': ('0','100'),\n",
        "        'pitch_shift': ('0','100')}\n",
        "\n",
        "# set up source\n",
        "sources = Objects(data.keys())\n",
        "sources.fromdict(data)\n",
        "sources.apply_mapping_functions(map_lims=lims)\n",
        "\n",
        "soni = Sonification(score, sources, generator, system)\n",
        "soni.render()\n",
        "dobj = soni.notebook_display()\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAmJKKnlM-80"
      },
      "source": [
        "How about mapping a low-pass filter to flux density? \n",
        "\n",
        "*using a 'tonal' carrier, uncomment line for a 'textural' (or white noise) carrier*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nn1UPAZxEXy0"
      },
      "outputs": [],
      "source": [
        "display(Markdown(f\"### Sonifying in 1D using low-pass '`cutoff`' frequency:\"))\n",
        "\n",
        "# show light curve again, for reference\n",
        "plt.plot(time,flux)\n",
        "plt.xlabel(f'Time')\n",
        "plt.ylabel(f'Flux')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "%matplotlib notebook\n",
        "generator = Synthesizer()\n",
        "generator.modify_preset({'filter':'on'})\n",
        "\n",
        "# uncomment these lines to try a 'textural' sonification using white noise!\n",
        "# generator.load_preset('windy')\n",
        "# generator.preset_details('windy')\n",
        "\n",
        "# we use a (power!) 'chord' here to create more harmonic richness...\n",
        "notes = [[\"A2\", \"E3\", 'A3', 'E4']]\n",
        "score =  Score(notes, length)\n",
        "\n",
        "data = {'pitch':[0,1,2,3],\n",
        "        'time_evo':[time]*4,\n",
        "        'cutoff':[flux]*4}\n",
        "\n",
        "lims = {'time_evo': ('0','100'),\n",
        "        'cutoff': ('0','100')}\n",
        "\n",
        "# set up source\n",
        "sources = Objects(data.keys())\n",
        "sources.fromdict(data)\n",
        "plims = {'cutoff': (0.25,0.9)}\n",
        "sources.apply_mapping_functions(map_lims=lims, param_lims=plims)\n",
        "\n",
        "soni = Sonification(score, sources, generator, system)\n",
        "soni.render()\n",
        "dobj = soni.notebook_display()\n",
        "\n",
        "# change back in case cells are run out of order...\n",
        "generator.load_preset('pitch_mapper')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOVerUAeZlAh"
      },
      "source": [
        "In fact, there are many expressive properties of sound we could use to represent the data in a similar way. In `strauss` these are referred to as `mappable` properties. \n",
        "\n",
        "A subset of these can be used as an evolving property with the `Object` source class. These are referred to as `evolvable` properties. \n",
        "\n",
        "Lets show what's available:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvhfpdWZZjPt"
      },
      "outputs": [],
      "source": [
        "display(Markdown(f\"### ***'Mappable'*** properties:\"))\n",
        "for m in Sources.mappable:\n",
        "  display(Markdown(f' * `{m}` '))\n",
        "\n",
        "display(Markdown(f\"### ***'Evolvable'*** properties:\"))\n",
        "for m in Sources.evolvable:\n",
        "  display(Markdown(f' * `{m}` '))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6napS2OIt6K"
      },
      "source": [
        "We can play around with some of these `evolvable` properties here. Are all of these effective for this data? Could they be effective for other types of data representations?\n",
        "\n",
        "The `idx` variable below controls which evolvable property is selected from the `some_mappings` list. `idx` can be changed to a number from 0 to 5 inclusive to *'index'* a certain sound parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qs5lkyB5njUe"
      },
      "outputs": [],
      "source": [
        "# A list of some 'evolvable' mappings\n",
        "some_mappings = [\"volume\", \n",
        "                 \"phi\",\n",
        "                 \"volume_lfo/amount\", \n",
        "                 \"volume_lfo/freq_shift\",\n",
        "                 \"pitch_lfo/amount\", \n",
        "                 \"pitch_lfo/freq_shift\"]\n",
        "\n",
        "# change this (between 0 and 5) to select a different property to map...\n",
        "idx = 1\n",
        "\n",
        "# use a stereo system to allow 'phi' mapping (low pan left and high pan right)\n",
        "system = \"stereo\"\n",
        "\n",
        "display(Markdown(f\"### Sonifying in 1D using `evolvable` property - ***`{some_mappings[idx]}`***:\"))\n",
        "\n",
        "# show light curve again, for reference\n",
        "plt.plot(time,flux)\n",
        "plt.xlabel(f'Time')\n",
        "plt.ylabel(f'Flux')\n",
        "plt.show()\n",
        "\n",
        "%matplotlib notebook\n",
        "generator = Synthesizer()\n",
        "generator.modify_preset({'filter':'on',\n",
        "                         \"pitch_hi\":-1, \"pitch_lo\": 1,\n",
        "                         \"pitch_lfo\": {\"use\": \"on\", \n",
        "                                       \"amount\":1*(\"pitch_lfo/freq_shift\" == some_mappings[idx]), \n",
        "                                       \"freq\":3*5**(\"pitch_lfo/freq_shift\" != some_mappings[idx]), \n",
        "                                       \"phase\":0.25},\n",
        "                         \"volume_lfo\": {\"use\": \"on\", \n",
        "                                        \"amount\":1*(\"volume_lfo/freq_shift\" == some_mappings[idx]), \n",
        "                                        \"freq\":3*5**(\"volume_lfo/freq_shift\" != some_mappings[idx]), \n",
        "                                        \"phase\":0}\n",
        "                        })\n",
        "\n",
        "# try a different chord (stacking fifths)...\n",
        "notes = [[\"A2\",\"E3\",\"B4\",\"F#4\"]]\n",
        "\n",
        "# chords and can also be specified via chord names and base octave....\n",
        "# notes = \"Em6_3\"\n",
        "\n",
        "\n",
        "score =  Score(notes, length)\n",
        "\n",
        "data = {'pitch':[0,1,2,3],\n",
        "        'time_evo':[time]*4,\n",
        "        'cutoff':[0.9]*4,\n",
        "        'theta':[0.5]*4,\n",
        "        some_mappings[idx]:[(flux - flux.min())/(flux.max()-flux.min())]*4}\n",
        "\n",
        "lims = {'time_evo': ('0','100'),\n",
        "        \"volume\": ('0','100'), \n",
        "        \"phi\": (-0.5,1.5),\n",
        "        \"volume_lfo/amount\": ('0','100'), \n",
        "        \"volume_lfo/freq_shift\": ('0','100'),\n",
        "        \"pitch_lfo/amount\": ('0','100'), \n",
        "        \"pitch_lfo/freq_shift\": ('0','100')}\n",
        "\n",
        "# set up source\n",
        "sources = Objects(data.keys())\n",
        "sources.fromdict(data)\n",
        "plims = {'cutoff': (0.25,0.9)}\n",
        "sources.apply_mapping_functions(map_lims=lims, param_lims=plims)\n",
        "\n",
        "soni = Sonification(score, sources, generator, system)\n",
        "soni.render()\n",
        "dobj = soni.notebook_display()\n",
        "%matplotlib inline\n",
        "\n",
        "# change back in case cells are run out of order...\n",
        "generator.load_preset('pitch_mapper')\n",
        "system = 'mono'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox6vDc4qIB1A"
      },
      "source": [
        "### 3.X A Side Note About Presets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9eHQQ_cGzwm"
      },
      "source": [
        "You can see all the parameters that make up the default `Synthesizer` preset in a pop-up window:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_uxJlqqoZOU"
      },
      "outputs": [],
      "source": [
        "%pycat /usr/local/lib/python3.7/dist-packages/strauss/presets/synth/default.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsqFGB6ZG_yJ"
      },
      "source": [
        "... as well as the other presets we might want to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSvkP1eMooke"
      },
      "outputs": [],
      "source": [
        "ls -1 /usr/local/lib/python3.7/dist-packages/strauss/presets/synth/*.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irfXngv4HJpe"
      },
      "source": [
        "We can modify these presets at runtime (as we do in various examples throughout this session), or even write our own presets in `.yml` format.\n",
        "\n",
        "The `generator.preset()` function also accepts a filepath to a custom presets, where any changed preset parameters replace those in the `default` preset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svu0wV5akl24"
      },
      "source": [
        "## **5. Iterating through examples & pre-processing data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzbWbfqhk26e"
      },
      "source": [
        "ðŸš§ ***under construction*** ðŸš§"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNTjcJNolrGS"
      },
      "source": [
        "## **6. Sandbox & Miscellaneous Functions** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prKB8Zaml9lU"
      },
      "source": [
        "ðŸš§ ***under construction*** ðŸš§"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M3IlcHifl3dG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IzDjUBzACtZg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iPclOU20Cth8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ghaEJaJtCtni"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9umShH_KCts8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hCsQtQioCtyD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "MCE-nk67Lf5N",
        "ox6vDc4qIB1A"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyPKyd+9gNFtgcL4U2O08zwu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}