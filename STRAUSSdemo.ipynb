{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/james-trayford/AudibleUniverseWorkbooks/blob/group3/STRAUSSdemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXMXgH-xVgaX"
   },
   "source": [
    "Notebook prepared by **Dr James Trayford** - for queries please email [`james.trayford@port.ac.uk`](mailto:james.trayford@port.ac.uk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBwYdDYB9lCQ"
   },
   "source": [
    "To use this notebook (if you haven't already) you can first save a copy to your local drive by clicking `File > Save a Copy in Drive` and run on that copy. `Edit > Clear all outputs` on that copy should also ensure yopu have a clean version\n",
    " to start from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v47s4t152sZ6"
   },
   "source": [
    "## **0. Introduction**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EMw6AfO200J"
   },
   "source": [
    "We will be using the [STRAUSS code](https://github.com/james-trayford/strauss) for this activity\n",
    "\n",
    "<img src=\"https://github.com/james-trayford/strauss/blob/main/misc/strauss_logo.png?raw=true\">\n",
    "\n",
    "For reference, you can read an overview of the code (as well as detailed documentation) [at this link](https://strauss.readthedocs.io/en/latest/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZ7CisIn22sg"
   },
   "source": [
    "`strauss` is an open source, object-oriented python library intended to be a flexible toolkit and engine for sonification, allowing detailed low-level control over the sonification process. Simultaneously, casual users can quickly hear their data, adapting a library of python notebook templates for a range of applications. \n",
    "\n",
    "By analogy to visualisation, the intention is to provide something akin to a plotting library. A library allows users to make a variety of simple plots easily, but also the option to control all aspects of plots and adapt them to the intricacies of their data, for optimal presentation. \n",
    "\n",
    "By adopting a general approach, `strauss` is intended to sonify any form of data for users with differing expertise. `strauss` is work in progress, and benefits form user feedback - filling in this feedback will be very useful in making the code better!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0m0bIZRs7BaC"
   },
   "source": [
    "### **This notebook:** \n",
    "This notebook will demonstrate some of the ways in which `strauss` can be applied to sonify spectra. Alternative options may be demonstrated with commented out code ( i.e. lines of actual code preceded by `#`) - feel free to try these! Generally the goal of this notebook is to give some open examples to explore the code and experiment, so please do so! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMh0Lo6E8lc9"
   },
   "source": [
    "### **STRAUSS video**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQHg0a5Z5jB_"
   },
   "source": [
    "You can also run the below cell to see a 12 minute introduction video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IVzULp-G4ZMz"
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('yhSNM8ztSEk', width=800, height=600) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zJMkFJwTTC9"
   },
   "source": [
    "## **1. Setup:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bH3ld6PZP2vX"
   },
   "source": [
    "First, let's install `strauss`! Just run the code cell below.\n",
    "\n",
    "*We will use the `spectraliser` development branch for this notebook. Install can take a while - but you should only need to run it once!*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgF2VVpZPl_V"
   },
   "outputs": [],
   "source": [
    " !pip --quiet install git+https://github.com/james-trayford/strauss.git@spectraliser -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrRwGGvJdIP6"
   },
   "source": [
    "and also make a local copy of the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UqHJTrrTdBhB"
   },
   "outputs": [],
   "source": [
    " !git clone https://github.com/james-trayford/strauss.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4FQXd9fUkfr"
   },
   "source": [
    "Make plots appear in-line by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J9_unXRNUgim"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYvyH45vTR-b"
   },
   "source": [
    "Import the modules we need..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W0rPodqYQorM"
   },
   "outputs": [],
   "source": [
    "# strauss imports\n",
    "from strauss.sonification import Sonification\n",
    "from strauss.sources import Events, Objects\n",
    "from strauss import channels\n",
    "from strauss.score import Score\n",
    "from strauss.generator import Sampler, Synthesizer, Spectralizer\n",
    "from strauss import sources as Sources \n",
    "import strauss\n",
    "\n",
    "# other useful modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.signal import savgol_filter\n",
    "import urllib.request\n",
    "import os\n",
    "import zipfile\n",
    "import glob\n",
    "import yaml\n",
    "\n",
    "# modules to display in-notebook\n",
    "import IPython.display as ipd\n",
    "from IPython.core.display import display, Markdown, Latex, Image\n",
    "\n",
    "# set figures to be a decent size by default\n",
    "import matplotlib\n",
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 18}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('figure', **{'figsize':[14.0, 7.0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kUJV_oI8mqD"
   },
   "source": [
    "## **2. Getting the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCFYP7KUP462"
   },
   "source": [
    "âš   ***The cells in this section are to organise the data we need for the session, don't worry too much about the details of the code here!*** âš  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nykq-9yBJAfE"
   },
   "source": [
    "First, let's download the data for this session to somewhere we have `Colab` access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cNnI7xN9lTM"
   },
   "outputs": [],
   "source": [
    "outdir = \"./AU2_Group3\"\n",
    "\n",
    "path = os.path.realpath(outdir)\n",
    "if not glob.glob(outdir): \n",
    "  os.mkdir(path)  \n",
    "    \n",
    "fname = \"Group3_input_data.zip\"\n",
    "url = \"https://drive.google.com/uc?export=download&id=1rLKWbajD6PV9qbMuWDrq0SaDnDCQSaSc\"\n",
    "\n",
    "print(f\"Downloading files...\")\n",
    "with urllib.request.urlopen(url) as response, open(f\"{path}/{fname}\", 'wb') as out_file:\n",
    "  data = response.read() # a `bytes` object\n",
    "  out_file.write(data)\n",
    "\n",
    "print(f\"Unzipping files to {outdir}/Data ...\")\n",
    "with zipfile.ZipFile(f\"{outdir}/{fname}\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(f\"{outdir}\")\n",
    "\n",
    "print(f\"Clearing up...\")\n",
    "os.remove(f\"{path}/{fname}\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVhfMKdWPGGh"
   },
   "source": [
    "Next, let's ***visually display these spectra*** and make a couple of ***data structures*** for easy \n",
    "access ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2WviFFdZPTaV"
   },
   "outputs": [],
   "source": [
    "types = [\"Type 1\", \"Type 1.5\", \"Type 2\"]\n",
    "\n",
    "spectra = {}\n",
    "spectra_plots = {}\n",
    "\n",
    "for t in types:\n",
    "  display(Markdown(f\"### **{t} spectra:**\"))\n",
    "  spectra_plots[t] = {}\n",
    "  spectra[t] = {}\n",
    "  for img in glob.glob(f\"./AU2_Group3/Data/{t.replace(' ', '')}/*.png\"):\n",
    "    display(Image(filename = img))\n",
    "  for csv in glob.glob(f\"./AU2_Group3/Data/{t.replace(' ', '')}/*.csv\"):\n",
    "    spectrum = np.genfromtxt(csv, delimiter=',')[1:]\n",
    "    label = '-'.join(csv.split('/')[-1].split('.')[0].split('-')[1:])\n",
    "    spectra[t][label] = spectrum\n",
    "    spectra_plots[t][label] = '.'.join(csv[:-3].split('.')[:-1]) + \".png\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGluXHJHYGqS"
   },
   "source": [
    "We now have access to all the spectra in the `data` object - let's see what's available for ***Type 1*** first..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WAbG8PNrYDof"
   },
   "outputs": [],
   "source": [
    "# show available types:\n",
    "print(\"Spectral types: \\n\", list(spectra.keys()), '\\n')\n",
    "\n",
    "# show available 'Type 1' examples:\n",
    "print(\"Type 1 spectra: \\n\", list(spectra[\"Type 1\"].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xj0SL6w4ZvDf"
   },
   "source": [
    "Finally, let's generate a plot of one of the ***Type 1*** spectrum `'51788-0386-086'` ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfpN7TmXaLQh"
   },
   "outputs": [],
   "source": [
    "# we stored the spectra as numpy arrays, where axis 0 is wavelength...\n",
    "wavelength = spectra['Type 1']['51788-0386-086'][:,0]\n",
    "\n",
    "# ... and axis 1 is flux density...\n",
    "flux = spectra['Type 1']['51788-0386-086'][:,1]\n",
    "\n",
    "plt.plot(wavelength, flux)\n",
    "plt.ylabel('Flux Density')\n",
    "plt.xlabel('Wavelength [nm]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MO4y_pIS0_No"
   },
   "source": [
    "## **3. One-dimensional time series sonification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FF0wzdSYjvp7"
   },
   "source": [
    "Here we will sonify spectra as a ***one-dimensional time series*** , where some ***sound property*** is is varied with ***time*** in the ***sonification***, in the same way that **flux density**, varies with ***wavelength*** in a ***spectrum*** (early in the sonification is shorter wavelengths, later is longer wavelengths). This approach in general is covered in more detail in the [other activity workbook](https://github.com/james-trayford/AudibleUniverseWorkbooks/blob/group4/STRAUSSdemo.ipynb)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCE-nk67Lf5N"
   },
   "source": [
    "### 3.1 Trying the `Events` source function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4DnjcHnSsLd"
   },
   "source": [
    "In `strauss` we could treat each ***flux density*** data point in the spectra as separate audio `Events`, with an occurence `time` mapped from their ***wavelength***. \n",
    "\n",
    "However, articulating each data point as a separate ***note*** for ***many thousands*** of data points can require long and drawn-out sonifications. \n",
    "\n",
    "Here we demonstrate this approach with just a portion of the data points (staying within `Colab`'s RAM limitations for unpaid users ðŸ¤«). We use the `Synthesizer` object with the `pitch_mapper` preset by default - this has a default pitch range of ***two octaves*** (a factor of 4 in frequency) and we pick an `E3` note (165 Hz) as the base (lowest) frequency.\n",
    "\n",
    "We will hear the **flux** of each point as `pitch`, with their wavelength mapped to the occurence `time` (moving from low to high wavelength). we can hear the general descent and some emission peaks, as well as the fact that the wavelength spacing gets **wider** as we go on. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0ibVd2VLdzd"
   },
   "outputs": [],
   "source": [
    "display(Markdown(f\"### Sonifying in 1D using '`Events`' object:\"))\n",
    "\n",
    "# show spectrum again, for reference\n",
    "plt.scatter(wavelength[1000:2000], flux[1000:2000], s=4)\n",
    "plt.ylabel('Flux Density')\n",
    "plt.xlabel('Wavelength [nm]')\n",
    "plt.show()\n",
    "\n",
    "%matplotlib notebook\n",
    "# specify the base notes used. In this example we use a single E3 note and \n",
    "# freely vary the pitch via the 'pitch_shift' parameter \n",
    "notes = [[\"E3\"]]\n",
    "\n",
    "# we could also just specify a particular frequency...\n",
    "#notes = [[150.]]\n",
    "\n",
    "score =  Score(notes, 80)\n",
    "\n",
    "\n",
    "data = {'pitch':np.ones(flux.size)[1000:2000],\n",
    "        'time': wavelength[1000:2000],\n",
    "        'pitch_shift':flux[1000:2000]}\n",
    "\n",
    "# specify audio system (e.g. mono, stereo, 5.1, ...)\n",
    "system = \"mono\"\n",
    "\n",
    "# set up synth (this generates the sound using mathematcial waveforms)\n",
    "generator = Synthesizer()\n",
    "generator.load_preset('pitch_mapper')\n",
    "\n",
    "# or maybe the sampler instead by uncommenting this block (this uses recorded audio clips)\n",
    "# generator = Sampler(sampfiles=\"./strauss/data/samples/mallets\")\n",
    "# generator.modify_preset({'phi': 0,'theta':0,})\n",
    "\n",
    "generator.modify_preset({'note_length':0.1,\n",
    "                         'volume_envelope': {'use':'on',\n",
    "                                             'D':0.1,\n",
    "                                             'S':0.,\n",
    "                                             'A':0.001}})\n",
    "\n",
    "# set 0 to 100 percentile limits so the full pitch range is used...\n",
    "# setting 0 to 101 for pitch means the sonification is 1% longer than \n",
    "lims = {'time': ('0','101'),\n",
    "        'pitch_shift': ('0','100')}\n",
    "\n",
    "# set up source\n",
    "sources = Events(data.keys())\n",
    "sources.fromdict(data)\n",
    "sources.apply_mapping_functions(map_lims=lims)\n",
    "\n",
    "soni = Sonification(score, sources, generator, system)\n",
    "soni.render()\n",
    "dobj = soni.notebook_display()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWkgTFk3T5rL"
   },
   "source": [
    "The articulation of each note lets you hear each data point separately, but over many noisy data points can lead to a confusing result - it's hard to keep track of the fluxes and our pitch memory is challenged.\n",
    "\n",
    "Instead we can try ***smoothly evolving*** parameters, designating the spectra as an ***evolving `Object`*** source class. We demonstrate this in the following subsection `3.1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvWzJ2JrlrHP"
   },
   "source": [
    "### 3.2 Instead Trying the `Objects` Source Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohlCzjEysV3N"
   },
   "source": [
    "Let's first try the evolving `Object` approach without modifying the raw data in any way. In analogy to visual display, the `Event` representation is like plotting the spectrum as a scatter plot, while an `Object` representation is like plotting the spectrum as a continuous line.\n",
    "\n",
    " We set up some parameters for `strauss`, e.g. choosing a sonification length of `40` seconds. A longer sonification might let you hear more detail, but will take longer to listen to (and for `Colab` to load!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nD7c6QR1NiJ"
   },
   "outputs": [],
   "source": [
    "# specify audio system (e.g. mono, stereo, 5.1, ...)\n",
    "system = \"mono\"\n",
    "\n",
    "# length of the sonification in s\n",
    "length = 40.\n",
    "\n",
    "# set up synth and turn on LP filter\n",
    "generator = Synthesizer()\n",
    "generator.load_preset('pitch_mapper')\n",
    "generator.preset_details('pitch_mapper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woJrlbVGcsmP"
   },
   "source": [
    "Let's pick a spectrum to sonify (as in Section 2). We will again default to ***Type 1*** spectrum `'51788-0386-086'`.\n",
    "\n",
    "Try changing this if you want to explore different spectra!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMp2Wq5Ocmq1"
   },
   "outputs": [],
   "source": [
    "stype = \"Type 1\"\n",
    "slabel = \"51788-0386-086\"\n",
    "\n",
    "# we stored the spectra as numpy arrays, where axis 0 is wavelength...\n",
    "wavelength = spectra[stype][slabel][:,0]\n",
    "\n",
    "# ... and axis 1 is flux density.\n",
    "flux = spectra[stype][slabel][:,1]\n",
    "\n",
    "# Finally, can use this to remind ourselves what the spectrum looks like...\n",
    "display(Image(spectra_plots[stype][slabel]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0K2YmC4C18a"
   },
   "source": [
    "let's hear the 1D time-series data sonification, mapping flux density to pitch for the spectrum.\n",
    "\n",
    "*NB: If you were wondering why `strauss` refers to the varying pitch mapping as `pitch_shift` and not just `pitch`, this is because all sources in `strauss` also need a base `pitch` which is chosen from the `'notes'` structure (here always `'A2'`) by the `Score`. This is because `strauss` can play many sources at the same time! Again, you can read more about this [in the docs](https://strauss.readthedocs.io/en/latest/).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeBqkWEk1Zny"
   },
   "outputs": [],
   "source": [
    "display(Markdown(f\"### Sonifying in 1D using '`pitch_shift`':\"))\n",
    "\n",
    "# show spectrum again, for reference\n",
    "display(Image(spectra_plots[stype][slabel]))\n",
    "\n",
    "%matplotlib notebook\n",
    "notes = [[\"A2\"]]\n",
    "score =  Score(notes, length)\n",
    "\n",
    "data = {'pitch':1.,\n",
    "        'time_evo':wavelength,\n",
    "        'pitch_shift':flux}\n",
    "\n",
    "# set 0 to 100 percentile limits so the full pitch and time range is used...\n",
    "lims = {'time_evo': ('0','100'),\n",
    "        'pitch_shift': ('0','100')}\n",
    "\n",
    "# set up source\n",
    "sources = Objects(data.keys())\n",
    "sources.fromdict(data)\n",
    "sources.apply_mapping_functions(map_lims=lims)\n",
    "\n",
    "soni = Sonification(score, sources, generator, system)\n",
    "soni.render()\n",
    "dobj = soni.notebook_display()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAmJKKnlM-80"
   },
   "source": [
    "How about mapping a low-pass filter to flux density? \n",
    "\n",
    "*using a 'tonal' carrier, uncomment line for a 'textural' (or white noise) carrier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nn1UPAZxEXy0"
   },
   "outputs": [],
   "source": [
    "display(Markdown(f\"### Sonifying in 1D using low-pass '`cutoff`' frequency:\"))\n",
    "\n",
    "# show spectrum again, for reference\n",
    "display(Image(spectra_plots[stype][slabel]))\n",
    "\n",
    "%matplotlib notebook\n",
    "generator = Synthesizer()\n",
    "generator.modify_preset({'filter':'on'})\n",
    "\n",
    "# uncomment these lines to try a 'textural' sonification using white noise!\n",
    "# generator.load_preset('windy')\n",
    "# generator.preset_details('windy')\n",
    "\n",
    "# we use a (power!) 'chord' here to create more harmonic richness...\n",
    "notes = [[\"A2\", \"E3\", 'A3', 'E4']]\n",
    "score =  Score(notes, length)\n",
    "\n",
    "data = {'pitch':[0,1,2,3],\n",
    "        'time_evo':[wavelength]*4,\n",
    "        'cutoff':[flux]*4}\n",
    "\n",
    "lims = {'time_evo': ('0','100'),\n",
    "        'cutoff': ('0','100')}\n",
    "\n",
    "# set up source\n",
    "sources = Objects(data.keys())\n",
    "sources.fromdict(data)\n",
    "plims = {'cutoff': (0.25,0.9)}\n",
    "sources.apply_mapping_functions(map_lims=lims, param_lims=plims)\n",
    "\n",
    "soni = Sonification(score, sources, generator, system)\n",
    "soni.render()\n",
    "dobj = soni.notebook_display()\n",
    "\n",
    "# change back in case cells are run out of order...\n",
    "generator.load_preset('pitch_mapper')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOVerUAeZlAh"
   },
   "source": [
    "In fact, there are many expressive properties of sound we could use to represent the data in a similar way. In `strauss` these are referred to as `mappable` properties. \n",
    "\n",
    "A subset of these can be used as an evolving property with the `Object` source class. These are referred to as `evolvable` properties. \n",
    "\n",
    "Lets show what's available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZvhfpdWZZjPt"
   },
   "outputs": [],
   "source": [
    "display(Markdown(f\"### ***'Mappable'*** properties:\"))\n",
    "for m in Sources.mappable:\n",
    "  display(Markdown(f' * `{m}` '))\n",
    "\n",
    "display(Markdown(f\"### ***'Evolvable'*** properties:\"))\n",
    "for m in Sources.evolvable:\n",
    "  display(Markdown(f' * `{m}` '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6napS2OIt6K"
   },
   "source": [
    "We can play around with some of these `evolvable` properties here. Are all of these effective for this data? Could they be effective for other types of data representations?\n",
    "\n",
    "The `idx` variable below controls which evolvable property is selected from the `some_mappings` list. `idx` can be changed to a number from 0 to 5 inclusive to *'index'* a certain sound parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qs5lkyB5njUe"
   },
   "outputs": [],
   "source": [
    "# A list of some 'evolvable' mappings\n",
    "some_mappings = [\"volume\", \n",
    "                 \"phi\",\n",
    "                 \"volume_lfo/amount\", \n",
    "                 \"volume_lfo/freq_shift\",\n",
    "                 \"pitch_lfo/amount\", \n",
    "                 \"pitch_lfo/freq_shift\"]\n",
    "\n",
    "# change this (between 0 and 5) to select a different property to map...\n",
    "idx = 0\n",
    "\n",
    "# use a stereo system to allow 'phi' mapping (low pan left and high pan right)\n",
    "system = \"stereo\"\n",
    "\n",
    "display(Markdown(f\"### Sonifying in 1D using `evolvable` property - ***`{some_mappings[idx]}`***:\"))\n",
    "\n",
    "# show spectrum again, for reference\n",
    "display(Image(spectra_plots[stype][slabel]))\n",
    "\n",
    "%matplotlib notebook\n",
    "generator = Synthesizer()\n",
    "generator.modify_preset({'filter':'on',\n",
    "                         \"pitch_hi\":-1, \"pitch_lo\": 1,\n",
    "                         \"pitch_lfo\": {\"use\": \"on\", \n",
    "                                       \"amount\":1*(\"pitch_lfo/freq_shift\" == some_mappings[idx]), \n",
    "                                       \"freq\":3*5**(\"pitch_lfo/freq_shift\" != some_mappings[idx]), \n",
    "                                       \"phase\":0.25},\n",
    "                         \"volume_lfo\": {\"use\": \"on\", \n",
    "                                        \"amount\":1*(\"volume_lfo/freq_shift\" == some_mappings[idx]), \n",
    "                                        \"freq\":3*5**(\"volume_lfo/freq_shift\" != some_mappings[idx]), \n",
    "                                        \"phase\":0}\n",
    "                        })\n",
    "\n",
    "# try a different chord (stacking fifths)...\n",
    "notes = [[\"A2\",\"E3\",\"B4\",\"F#4\"]]\n",
    "\n",
    "# chords and can also be specified via chord names and base octave....\n",
    "# notes = \"Em6_3\"\n",
    "\n",
    "\n",
    "score =  Score(notes, length)\n",
    "\n",
    "data = {'pitch':[0,1,2,3],\n",
    "        'time_evo':[wavelength]*4,\n",
    "        'cutoff':[0.9]*4,\n",
    "        'theta':[0.5]*4,\n",
    "        some_mappings[idx]:[flux/flux.max()]*4}\n",
    "\n",
    "lims = {'time_evo': ('0','100'),\n",
    "        \"volume\": ('0','100'), \n",
    "        \"phi\": (-0.5,1.5),\n",
    "        \"volume_lfo/amount\": ('0','100'), \n",
    "        \"volume_lfo/freq_shift\": ('0','100'),\n",
    "        \"pitch_lfo/amount\": ('0','100'), \n",
    "        \"pitch_lfo/freq_shift\": ('0','100')}\n",
    "\n",
    "# set up source\n",
    "sources = Objects(data.keys())\n",
    "sources.fromdict(data)\n",
    "plims = {'cutoff': (0.25,0.9)}\n",
    "sources.apply_mapping_functions(map_lims=lims, param_lims=plims)\n",
    "\n",
    "soni = Sonification(score, sources, generator, system)\n",
    "soni.render()\n",
    "dobj = soni.notebook_display()\n",
    "%matplotlib inline\n",
    "\n",
    "# change back in case cells are run out of order...\n",
    "generator.load_preset('pitch_mapper')\n",
    "system = 'mono'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ox6vDc4qIB1A"
   },
   "source": [
    "### 3.X A Side Note About Presets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9eHQQ_cGzwm"
   },
   "source": [
    "You can see all the parameters that make up the default `Synthesizer` preset in a pop-up window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_uxJlqqoZOU"
   },
   "outputs": [],
   "source": [
    "%pycat /usr/local/lib/python3.7/dist-packages/strauss/presets/synth/default.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsqFGB6ZG_yJ"
   },
   "source": [
    "... as well as the other presets we might want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rSvkP1eMooke"
   },
   "outputs": [],
   "source": [
    "ls -1 /usr/local/lib/python3.7/dist-packages/strauss/presets/synth/*.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irfXngv4HJpe"
   },
   "source": [
    "We can modify these presets at runtime (as we do in various examples throughout this session), or even write our own presets in `.yml` format.\n",
    "\n",
    "The `generator.preset()` function also accepts a filepath to a custom presets, where any changed preset parameters replace those in the `default` preset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pi0WrB-00Am"
   },
   "source": [
    "## **4. \"Spectralizer\" sonification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdDuniFWwkg6"
   },
   "source": [
    "Now, we will try converting the ***light spectrum*** into a ***sound spectrum*** directly, i.e. the sound has the same frequency features as the observed spectrum, albeit at ***audible frequencies*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nz33ADvIrMRA"
   },
   "source": [
    "Set up some STRAUSS stuff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKcYzEpNROFh"
   },
   "outputs": [],
   "source": [
    "# specify audio system (e.g. mono, stereo, 5.1, ...)\n",
    "system = \"mono\"\n",
    "length = 10\n",
    "\n",
    "# set uo score object for sonification\n",
    "score =  Score([\"C3\"], length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_H761plzvos"
   },
   "source": [
    "sonify the spectrum..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UMs1q4pAUAr_"
   },
   "outputs": [],
   "source": [
    "# show spectrum again, for reference\n",
    "display(Image(spectra_plots[stype][slabel]))\n",
    "\n",
    "# set up spectralizer generator\n",
    "generator = Spectralizer()\n",
    "\n",
    "# set up spectrum and choose some envelope parameters for fade-in and fade-out\n",
    "data = {'spectrum':[flux[::-1]], 'pitch':[1],\n",
    "        'volume_envelope/D':[0.9], \n",
    "        'volume_envelope/S':[0.], \n",
    "        'volume_envelope/A':[0.05]}\n",
    "\n",
    "# again, use maximal range for the mapped parameters\n",
    "lims = {'spectrum': ('0','100')}\n",
    "\n",
    "# set up source\n",
    "sources = Events(data.keys())\n",
    "sources.fromdict(data)\n",
    "sources.apply_mapping_functions(map_lims=lims)\n",
    "\n",
    "# render and play sonification!\n",
    "soni = Sonification(score, sources, generator, system)\n",
    "soni.render()\n",
    "soni.save('spectralize1.wav')\n",
    "ipd.Audio('spectralize1.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRThZITexfSc"
   },
   "source": [
    "We can try the same thing, but what if we vary the ***sound frequency range*** the spectrum is mapped to? \n",
    "\n",
    "This can be done by changing the `Spectralizer` generator preset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwbMQ8ipxcu-"
   },
   "outputs": [],
   "source": [
    "# we can modify the frequency range (in Hz) like this: \n",
    "generator.modify_preset({'min_freq':500, 'max_freq':2000})\n",
    "\n",
    "# We could try any range we like (though Colab might crash from lack of RAM if we try extreme options...)\n",
    "#generator.modify_preset({'min_freq':20, 'max_freq':22000})\n",
    "#generator.modify_preset({'min_freq':250, 'max_freq':4000})\n",
    "\n",
    "# Particularly, if we want to preserve harmonic relations, need to set the minimum and maximum frequency \n",
    "# such that the sonified spectrum spans the same range in log frequency as the original light spectrum\n",
    "# can do this in the loop to ensure this is true for each spectrum \n",
    "\n",
    "#generator.modify_preset({'min_freq':100, 'max_freq':100*min(wavelength)/max(wavelength)})  \n",
    "\n",
    "# render and play sonification!\n",
    "soni = Sonification(score, sources, generator, system)\n",
    "soni.render()\n",
    "soni.save('spectralize2.wav')\n",
    "display(ipd.Audio('spectralize2.wav'))\n",
    "\n",
    "# reset preset to default now we've made the sonification...\n",
    "generator.load_preset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UboXSm8cyDUn"
   },
   "source": [
    "Are certain ranges better for hearing features? Is using the full range of human hearing (about 20 Hz to 22kHz) optimal?\n",
    "\n",
    "Can you set up a way to try different ranges systematically?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Svu0wV5akl24"
   },
   "source": [
    "## **5. Iterating through examples & pre-processing data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzbWbfqhk26e"
   },
   "source": [
    "ðŸš§ ***under construction*** ðŸš§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7roRhiEXB5N7"
   },
   "source": [
    "### **5.1 Cycling through the spectra**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3-6lxrHoIb1"
   },
   "source": [
    "Let's iterate through all these spectra we've got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8IxSxwOHks_b"
   },
   "outputs": [],
   "source": [
    "for t in spectra.keys():\n",
    "    display(Markdown(f\"### **{t} spectra:**\"))\n",
    "    for s in spectra[t].keys():\n",
    "      display(Markdown(f\"* ID <mark>`{s}`</mark> (available as <mark>`spectra['{t}']['{s}']`</mark>)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOOrrbDhrcoy"
   },
   "source": [
    "For example, Let's spectralise each of these `'Type 1'` spectra "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3lp7Nnt4rG0x"
   },
   "outputs": [],
   "source": [
    "# can set up generator, limits and most of the data mapping dictionary \n",
    "# outside of the loop  \n",
    "generator = Spectralizer()\n",
    "\n",
    "data = {'pitch':[1],\n",
    "        'volume_envelope/D':[0.9], \n",
    "        'volume_envelope/S':[0.], \n",
    "        'volume_envelope/A':[0.05]}\n",
    "\n",
    "lims = {'spectrum': ('0','100')}\n",
    "\n",
    "# now loop through spectra...\n",
    "for t in spectra.keys():\n",
    "\n",
    "  # only do stuff for the 'Type 1's... can change this or comment out!\n",
    "  if t == \"Type 1\":\n",
    "    display(Markdown(f\"### **{t} spectra:**\"))\n",
    "    for s in spectra[t].keys():\n",
    "      wavelength = spectra[t][s][:,0]\n",
    "    \n",
    "      # if we want to preserve harmonic relations, need to set the minimum and maximum frequency \n",
    "      # such that the sonified spectrum spans the same range in log frequency as the original light spectrum\n",
    "      # can do this in the loop to ensure this is true for each spectrum \n",
    "      \n",
    "      #generator.modify_preset({'min_freq':100, 'max_freq':100*min(wavelength)/max(wavelength)})  \n",
    "        \n",
    "      flux = spectra[t][s][:,1]\n",
    "      \n",
    "      # show spectrum again, for reference\n",
    "      display(Image(spectra_plots[t][s], width=500,height=400))\n",
    "      display(Markdown(f\"* ID <mark>`{s}`</mark>\"))\n",
    "\n",
    "      # set the spectrum to use...\n",
    "      data['spectrum'] = [flux[::-1]]\n",
    "\n",
    "\n",
    "      # set up source\n",
    "      sources = Events(data.keys())\n",
    "      sources.fromdict(data)\n",
    "      sources.apply_mapping_functions(map_lims=lims)\n",
    "\n",
    "      # render and play sonification!\n",
    "      soni = Sonification(score, sources, generator, system)\n",
    "      soni.render()\n",
    "      soni.save(f\"spectralize_{t.replace(' ', '')}_{s}.wav\")\n",
    "      display(ipd.Audio(f\"spectralize_{t.replace(' ', '')}_{s}.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0J8db75H0ScG"
   },
   "source": [
    "The noisy component you hear in some of these examples is associated with ***the continuum*** (the shape of the spectrum ignoring the spiky features). Having a non-zero flux density over a broad range of wavelengths leads to a ***'noisy'*** sound as tone combine over a broad range in frequency. We will address this in the next subsection `5.2`..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGZmF4-pCD1S"
   },
   "source": [
    "### **5.2 Pre-processing the data: Subtracting a continuum**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HL68ZReJCIBC"
   },
   "source": [
    "One way we can process this data is by ***fitting a continuum*** and ***subtracting it away***, leaving only those tasty ***spectral lines***. We'll also fit to the **logarithm** of the flux, which will stop the spiky features influencing the fit so much. Here's a simple function to do that fitting \n",
    "\n",
    "*Rough fits for now, but demonstrates the effect! - can you do better?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cluZ1TTh1syN"
   },
   "outputs": [],
   "source": [
    "# fit polynomial continuum to x-y dat and choosing a polynomial 'order' \n",
    "# (i.e. for order=3 we find A,B,C,D for the Ax^3 + Bx^2 + Cx + D that best fits)\n",
    "# we mask out sharp spikes and fit to the inverted spectrum to try and represent\n",
    "# the base continuum level. \n",
    "def log_poly(x,y,order=10):\n",
    "    # set a minimum flux to avoid breaking log function\n",
    "    yclip = np.clip(y, 10,np.inf)\n",
    "    lyclip = np.log10(yclip)\n",
    "    bdx = yclip.astype(bool)\n",
    "    lysmooth = savgol_filter(np.log10(yclip),501, 3)\n",
    "    bdx = lyclip < lysmooth\n",
    "    p = np.polyfit(x[bdx],1/yclip[bdx],order).reshape(1, order+1)\n",
    "    exps = np.arange(order+1)[::-1].reshape(1,order+1)\n",
    "    ypol = 1/((pow(x.reshape(x.size,1), exps) * p).sum(1))\n",
    "    return ypol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3f-fEO4z38SA"
   },
   "source": [
    "So let's do the same thing again, but now subtract the continuum away and clip values below the continuum to just get ***emission lines***.\n",
    "\n",
    "We'll also make some plots to illustrate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "EZvn8vKz4O8w"
   },
   "outputs": [],
   "source": [
    "# can set up generator, limits and most of the data mapping dictionary \n",
    "# outside of the loop  \n",
    "generator = Spectralizer()\n",
    "#generator.modify_preset({'min_freq':250, 'max_freq':1000})\n",
    "\n",
    "data = {'pitch':[1],\n",
    "        'volume_envelope/D':[0.9], \n",
    "        'volume_envelope/S':[0.], \n",
    "        'volume_envelope/A':[0.05]}\n",
    "\n",
    "lims = {'spectrum': ('0','100')}\n",
    "\n",
    "# now loop through spectra...\n",
    "for t in spectra.keys():\n",
    "\n",
    "  # only do stuff for the 'Type 1's... can change this or comment out!\n",
    "  #if t == \"Type 1\":\n",
    "    display(Markdown(f\"### **{t} spectra:**\"))\n",
    "    for s in spectra[t].keys():\n",
    "      wavelength = spectra[t][s][:,0]\n",
    "    \n",
    "      # if we want to preserve harmonic relations, need to set the minimum and maximum frequency \n",
    "      # such that the sonified spectrum spans the same range in log frequency as the original light spectrum\n",
    "      # can do this in the loop to ensure this is true for each spectrum \n",
    "        \n",
    "      #generator.modify_preset({'min_freq':100, 'max_freq':100*min(wavelength)/max(wavelength)})\n",
    "    \n",
    "      flux = spectra[t][s][:,1]\n",
    "      continuum = log_poly(wavelength, flux)\n",
    "\n",
    "      # subtract continuum and take only positive fluxes...\n",
    "      flux_csub = np.clip(flux - continuum, 0, np.inf)\n",
    "\n",
    "      # set the spectrum to use...\n",
    "      data['spectrum'] = [flux_csub[::-1]]\n",
    "\n",
    "      # what would the continuum sound like on its own?\n",
    "      #data['spectrum'] = [continuum[::-1]]\n",
    "\n",
    "      # what about flipping the spectrum so we hear what's below the continuum?\n",
    "      #data['spectrum'] = [np.clip(continuum - flux, 0, np.inf)[::-1]]\n",
    "\n",
    "      # Plotting bit ========================================\n",
    "      fig = plt.figure(figsize=(15,6))\n",
    "      ax1 = fig.add_subplot(121)\n",
    "      ax1.plot(wavelength, flux, label='Raw flux')\n",
    "      ax1.plot(wavelength, continuum, lw=5, alpha=0.5, label='Continuum fit')\n",
    "      plt.xlabel(\"Wavelength [nm]\")\n",
    "      plt.ylabel(\"Flux Density\")   \n",
    "      plt.legend(frameon=0)\n",
    "      ax2 = fig.add_subplot(122)\n",
    "      ax2.plot(np.linspace(generator.preset['min_freq'],\n",
    "                           generator.preset['max_freq'],\n",
    "                           flux.size), data['spectrum'][0], c='k', label='Sonified spectrum')  \n",
    "      plt.xlabel(\"Frequency [Hz]\") \n",
    "      plt.ylabel(\"Flux Density (Continuum Subtracted)\")\n",
    "      plt.ylim(-10,flux.max())   \n",
    "      plt.legend(frameon=0)\n",
    "      plt.show()\n",
    "      display(Markdown(f\"* ID <mark>`{s}`</mark>\"))\n",
    "      # =====================================================\n",
    "\n",
    "      # set up source\n",
    "      sources = Events(data.keys())\n",
    "      sources.fromdict(data)\n",
    "      sources.apply_mapping_functions(map_lims=lims)\n",
    "\n",
    "      # render and play sonification!\n",
    "      soni = Sonification(score, sources, generator, system)\n",
    "      soni.render()\n",
    "      soni.save(f\"spectralize_{t.replace(' ', '')}_{s}.wav\")\n",
    "      display(ipd.Audio(f\"spectralize_{t.replace(' ', '')}_{s}.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNTjcJNolrGS"
   },
   "source": [
    "## **6. Sandbox & Miscellaneous Functions** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prKB8Zaml9lU"
   },
   "source": [
    "ðŸš§ ***under construction*** ðŸš§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "M3IlcHifl3dG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "IzDjUBzACtZg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "iPclOU20Cth8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ghaEJaJtCtni"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9umShH_KCts8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hCsQtQioCtyD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNZ/uR22g1If1EBnsXEOOVw",
   "collapsed_sections": [
    "MCE-nk67Lf5N",
    "ox6vDc4qIB1A"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
